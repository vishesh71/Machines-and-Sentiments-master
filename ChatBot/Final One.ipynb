{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11527, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from rake_nltk import Rake\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#nltk.download('popular', quiet=True) # for downloading packages\n",
    "#!pip3 install rake-nltk\n",
    "\n",
    "\n",
    "#print(\"\\nROBO: So you want to see a new movie now right?\")\n",
    "\n",
    "df_movies = pd.read_csv(\"IMDb movies.csv\")\n",
    "df_ratings = pd.read_csv(\"IMDb ratings.csv\")\n",
    "with open('chatbot.txt','r', encoding='utf8', errors ='ignore') as fin:\n",
    "    raw = fin.read().lower()\n",
    "\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words\n",
    "\n",
    "lemmer = WordNetLemmatizer()\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"how are you\",\"hey\",\"Hi Bot\", \"Hi\")\n",
    "GREETING_RESPONSES = [\"Hi\", \"Hey\", \"*nods*\", \"Hi there\", \"Hello\",\"Hi dude, Im good\", \"I am glad! You are talking to me\"]\n",
    "\n",
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "df_movies = df_movies[['imdb_title_id','title', 'duration', 'year', 'genre', 'language', 'actors', 'director','description']]\n",
    "df_ratings = df_ratings[['imdb_title_id', 'mean_vote', 'weighted_average_vote','median_vote', 'total_votes']]\n",
    "df = pd.merge(df_movies, df_ratings, on='imdb_title_id')\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "df2 = df[df['language'].str.contains(r'English')]\n",
    "df2 = df2.loc[(df2['mean_vote'] >= 6) & (df['total_votes'] >= 2000)] # Take all English Movies with Rating greater than 6\n",
    "df2 = df2[df2['year'] >= 1970]\n",
    "df3 = df[df['language'].str.contains(r'Tamil|Kannada|Telugu|Hindi|Malayalam')]\n",
    "df3 = df3[(df3['mean_vote'] >= 5) & (df3['total_votes'] >= 500)]\n",
    "\n",
    "df = pd.concat([df2,df3])\n",
    "df = df.apply(lambda x: x.str.lower() if(x.dtype == 'O') else x)\n",
    "df = df.drop_duplicates(subset=['title','year'], keep = 'last')\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Key_words'] = ''\n",
    "r = Rake()\n",
    "for index, row in df.iterrows():\n",
    "    r.extract_keywords_from_text(row['description'])\n",
    "    key_words_dict_scores = r.get_word_degrees()\n",
    "    row['Key_words'] = list(key_words_dict_scores.keys())\n",
    "    df['Key_words'][index] = row['Key_words']\n",
    "\n",
    "df['genre'] = df['genre'].map(lambda x: x.split(','))\n",
    "for index, row in df.iterrows():\n",
    "    row['genre'] = [x.lower().replace(' ','') for x in row['genre']]\n",
    "\n",
    "df['Bag_of_words'] = ''\n",
    "columns = ['Key_words', 'genre']\n",
    "for index, row in df.iterrows():\n",
    "    words = ''\n",
    "    for col in columns:\n",
    "        words += ' '.join(row[col]) + ' '\n",
    "    row['Bag_of_words'] = words\n",
    "    df['Bag_of_words'][index] = words\n",
    "dfn = df[['title','Bag_of_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_n_space(m1, m2, batch_size=10000):\n",
    "    assert m1.shape[1] == m2.shape[1]\n",
    "    ret = np.ndarray((m1.shape[0], m2.shape[0]))\n",
    "    for row_i in range(0, int(m1.shape[0] / batch_size) + 1):\n",
    "        start = row_i * batch_size\n",
    "        end = min([(row_i + 1) * batch_size, m1.shape[0]])\n",
    "        if end <= start:\n",
    "            break # cause I'm too lazy to elegantly handle edge cases\n",
    "        rows = m1[start: end]\n",
    "        sim = cosine_similarity(rows, m2) # rows is O(1) size\n",
    "        ret[start: end] = sim\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(dfn['Bag_of_words'])\n",
    "csmain = cosine_similarity_n_space(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(dfn['title'])\n",
    "def recommend(title, num=10, cosine_sim = csmain):\n",
    "    recommended_movies = []\n",
    "    try:\n",
    "        idx = indices[indices == title].index[0]\n",
    "        score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "        top_10_indices = list(score_series.iloc[1:num+1].index)\n",
    "\n",
    "        for i in top_10_indices:\n",
    "            recommended_movies.append(list(dfn['title'])[i])\n",
    "        print(\"\\nGreat Choice. Here is the list of similar movies:\")\n",
    "        k = 1;\n",
    "        for i in recommended_movies:\n",
    "            print(k,i.title())\n",
    "            k+=1;\n",
    "        return False\n",
    "    except:\n",
    "        print(\"ROBO: I'm sorry but I could not find such a movie in our Database.\")\n",
    "        print(\"ROBO: I'd recommend you to check the spelling of the movie you entered.\")\n",
    "        print(\"ROBO: Also make sure it belongs to the same genre and language you had entered before.\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"labeledTrainData.tsv\",sep=\"\\t\")\n",
    "data.head()\n",
    "X = data.review\n",
    "y = data.sentiment\n",
    "#Using CountVectorizer to convert text into tokens/features\n",
    "vect = CountVectorizer(stop_words='english', ngram_range = (1,1), max_df = .80, min_df = 4)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1, test_size= 0.2)\n",
    "#Using training data to transform text into counts of features for each message\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train_dtm, y_train)\n",
    "y_pred = NB.predict(X_test_dtm)\n",
    "#print('\\nNaive Bayes')\n",
    "#print('Accuracy Score: ',metrics.accuracy_score(y_test,y_pred)*100,'%',sep='')\n",
    "#print('Confusion Matrix: ',metrics.confusion_matrix(y_test,y_pred), sep = '\\n')\n",
    "\n",
    "tokens_words = vect.get_feature_names()\n",
    "#print('\\nAnalysis')\n",
    "#print('No. of tokens: ',len(tokens_words))\n",
    "counts = NB.feature_count_\n",
    "df_table = {'Token':tokens_words,'Negative': counts[0,:],'Positive': counts[1,:]}\n",
    "tokens = pd.DataFrame(df_table, columns= ['Token','Positive','Negative'])\n",
    "positives = len(tokens[tokens['Positive']>tokens['Negative']])\n",
    "#print('No. of positive tokens: ',positives)\n",
    "#print('No. of negative tokens: ',len(tokens_words)-positives)\n",
    "#Check positivity/negativity of specific tokens\n",
    "token_search = ['horrendous']\n",
    "#print('\\nSearch Results for token/s:',token_search)\n",
    "#print(tokens.loc[tokens['Token'].isin(token_search)])\n",
    "#Analyse False Negatives (Actual: 1; Predicted: 0)(Predicted negative review for a positive review) \n",
    "#print(X_test[ y_pred < y_test ])\n",
    "#Analyse False Positives (Actual: 0; Predicted: 1)(Predicted positive review for a negative review) \n",
    "#print(X_test[ y_pred > y_test ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=True\n",
    "print(\"ROBO: Hi there\")\n",
    "print(\"ROBO: My name is Robo. Type 'help' for guidance, 'review' to review a movie and let others know your opinion, 'recommend' so we can recommend you a movie based on your preference :)\")\n",
    "print(\"ROBO: Type Quit to exit.\")\n",
    "\n",
    "while(flag==True):\n",
    "    print(\"\\nROBO: Enter Recommend or Review or Quit[to quit lol :)]\")\n",
    "    user_response = input().lower()\n",
    "    \n",
    "    if(user_response==r'recommend'):\n",
    "        ans = True\n",
    "        while (ans):\n",
    "            print(\"ROBO: Please refer to Imdb for the exact movie Name.\")\n",
    "            user_res = input(\"Enter the movie which you have in mind.\\n\").lower()\n",
    "            num = int(input(\"How many such similar movies do you want??\\n\"))\n",
    "            ans = recommend(user_res,num)\n",
    "        print(\"\\nROBO: I think you will love to watch these movies.\")\n",
    "        print(\"ROBO: Do get back to us regarding your views on these films!!\")\n",
    "        flag = True\n",
    "        \n",
    "    elif(user_response==r'review'):\n",
    "        print(\"ROBO: Alright...\")  \n",
    "        print(\"ROBO: Give me a moment\")\n",
    "        trainingVector = CountVectorizer(stop_words='english', ngram_range = (1,1), max_df = .80, min_df = 5)\n",
    "        trainingVector.fit(X)\n",
    "        X_dtm = trainingVector.transform(X)\n",
    "        NB_complete = MultinomialNB()\n",
    "        NB_complete.fit(X_dtm, y)\n",
    "        #Input Review\n",
    "        print('\\nTest a custom review message')\n",
    "        mov_str = input(\"Enter the Movie Name.\\n\").lower()\n",
    "        print('Enter review to be analysed: ', end=\" \")\n",
    "        test = []\n",
    "        test.append(input())\n",
    "        test_dtm = trainingVector.transform(test)\n",
    "        predLabel = NB_complete.predict(test_dtm)\n",
    "        tags = ['Negative','Positive']\n",
    "        #Display Output\n",
    "        print('\\nThe review is predicted:',tags[predLabel[0]])\n",
    "        flag = True\n",
    "        \n",
    "        if tags[predLabel[0]] == 'Negative':\n",
    "            print(\"\\nROBO: Ohhh!! I don't think you liked that movie.\")\n",
    "            print(\"\\nROBO: We'll take a note of that. Thanks for contributing to our database\")\n",
    "        else:\n",
    "            print(\"\\nROBO: Ohhh!! That's great I think you could take a look at our Movie Recommender to watch Similar movies.\")\n",
    "            print(\"ROBO: We shall search our database to suggest similar movies to the one you have watched\")\n",
    "            print(\"ROBO: Give me a second.....\")\n",
    "            time.sleep(1)\n",
    "            ans = recommend(mov_str,10)\n",
    "            flag = True\n",
    "            \n",
    "    elif(greeting(user_response)!=None):\n",
    "        print(\"ROBO: \"+greeting(user_response))\n",
    "        flag = True\n",
    "        \n",
    "    elif(user_response == r'quit'):\n",
    "        print(\"ROBO: Thanks for calling me\")\n",
    "        print('ROBO: Bye! Have a good day')\n",
    "        flag = False\n",
    "    else :\n",
    "        print(\"Ohh I'm sorry I didnt get you. Please enter something valid\")\n",
    "        flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
